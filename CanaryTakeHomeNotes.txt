CanaryNotes
------------
Readme Notes:

docker-compose.yml was updated to set up pgadmin4 as well. This can be accessed from localhost:5050, but can be removed if not wanted. I needed a simple postgresql management interface.

I manually created seed data for an emission_sites and an equipment_groups table. That seed data is specified in ProjectCanaryDbContext.cs.

The backend is set up to allow cors specifically only in dev mode and only for requests from localhost:3000. So The frontend must run on that port.

The frontend requires a .env.local file to point it to the dotnet backend. The backend is currently configured to port 5134 when using the http profile, so the contents of this file should be
NEXT_PUBLIC_API_URL=http://localhost:5134
This would change if you are using iisExpress or another profile.

The frontend sorts by month by default.

If I had more time or had to make this similar to a production app, I would do the following:
* Add logging everywhere
* Do something more clever than catching all exceptions in controller methods. I am currently swallowing the exception messages because you usually wouldn't want the
  consumer of your api to see exception messages because it is ugly and also gives insight into your code. Having said that, catching all exceptions isn't terribly elegant.
  I would definitely try to return something like a 409 when the user attempts to upload duplicate data.
* Add more tests. 
* GetMeasuredVsEstimatedChartData in the EmissionsController converts month int string to month name when you are ordering by month. This is gross and difficult to read. I would find a cleaner way to do this.
* The month group by parameter is currently called YearAndMonth. In the real world, we would have results from multiple years so you would either have to display results from all months from all years that have data, or you would have to specify the year in your query. Since we only have data from 2023, this is not a problem in the take home.


Questions:
Is it okay to assume that the columns in the csv files will always be in the same order?

What parts of estimated and measured emissions should be considered to be unique? If a user attempts to upload
the same data twice, we wouldn't want duplciates in the system. For estimates, my guess would be every column 
except for MethaneInKg (Latitude,Longitude,EquipmentGroupName,Start). For measurements, I would expect to
be able to reduce that to EquipmentId, Start (assuming that it EquipmentId really is a unique id in the system).

also add an import id so that you can delete everything from a specific import if you need to.

There are emissions whose latitude/longitude don't exactly match any of the sites. Should I look for the closest site to determine which they should be associated with?
Is there a certain proximity that should be considered close enough? Or should I get rid of any data that isn't exactly at the site?

In the unlikely case that a start and end time straddle a month or even year boundary, how should they be counted? Towards the year and month of the start date?

---------------------------
More questions and thoughts
---------------------------
I am storing the start/end times as utc in postgres. Hopefully I can treat these as local times.


---------
DB Tables
---------

CREATE TABLE emission_site (
	site_id SERIAL primary key,
	name character(255) unique,
	latitude double precision,
	longitude double precision
);

CREATE TABLE equipment_group (
	equipment_group_id SERIAL primary key,
	name character(255) unique
);

CREATE TABLE equipment (
	equipment_group_id integer,
	equipment_id UUID,
	primary key (equipment_group_id, equipment_id)
)

CREATE TABLE measured_emissions (
	id bigserial primary key,
	site_id integer,
	equipment_group_id integer,
	equipment_id uuid,
	methane_in_kg double precision,
	measurement_start_time timestamp,
	measurement_end_time timestamp
)

CREATE TABLE estimated_emissions (
	id bigserial primary key,
	site_id integer,
	equipment_group_id integer,
	methane_in_kg double precision,
	estimate_start_time timestamp,
	estimate_end_time timestamp
)

INSERT INTO emission_site
(name, latitude, longitude)
values ('Blackstone Pad', 39.91413786,-80.4778364),
('Cedar Ridge Pad',40.08534879,-80.64617783),
('Eagle''s Nest Pad',33.14457495,-97.44019826),
('Pine Valley Pad',32.75879278,-97.26486679),
('Red Rock Pad',31.91391573,-93.29114089),
('Ironwood Pad',31.77769914,-93.43597152)

insert into equipment_group
(name)
values
('Dehydrators'),
('GPUs'),
('Meter Runs'),
('Produced Water Tanks'),
('Sand Traps'),
('Slug Catchers'),
('Slop Tanks'),
('Wells')

